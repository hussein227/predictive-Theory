{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "predictive theory",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flxpCp05J6o7"
      },
      "source": [
        "i will write every thing By my Hand"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6CRXJa8RaMs"
      },
      "source": [
        " Important steps in predictive analysis \n",
        "**data exploration(understanding the data like num of rows OR average values minimum values ),data cleaning(to get red of missing values),modelling(using linear regression to make relations between variables),perform analysis(this for effecincy)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sb3MD87SQSO"
      },
      "source": [
        "the common topic is  Data analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK1Uv_2sMWnL"
      },
      "source": [
        "Data procsesing (prepare your Data )\n",
        "feature imputation:Fillig up the missing values\n",
        "feature encoding:Turnning categorial values to num fourm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB4MfGpIhJkg"
      },
      "source": [
        "Data mining:\n",
        "1)Exploration:changing data to another fourm\n",
        "2)pattern\n",
        "3) Deployment:Using the pattern to get the purpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzSlBEBqhlTn"
      },
      "source": [
        "predictive analysis is subset of machinelearning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6d8rcdruCjT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivNo4riX2Zum"
      },
      "source": [
        "machine learning teqnique :Adaptive technique where the systems are smart enough to adapt and learn as and when a new set of data is added, without the need of being directly programmed. Previous calculations will be used to provide effective results\t\n",
        "predictive analysis:Models are known to make use of classifiers and detection theory to guess the probability of an outcome given a set of input data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG1xpBrD3AZz"
      },
      "source": [
        "Types of Machine Learning Models:\n",
        "Classification Models\n",
        "Regression Models\n",
        "Clustering\n",
        "Dimensionality Reduction\n",
        "Deep Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wz980v9UMq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkufW2_0E7qB"
      },
      "source": [
        "chossing An Algorithm in machine learning :\n",
        "(*) supervised ex:[logistic regression,Linear REgression,K- nearest neighbour,ADA boost,Decision Tree And Random forest,Support vector Model,neaural net,deep learning ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEP3KmUlFzLy"
      },
      "source": [
        "Predictive analytics :involves certain manipulations on data from existing data sets with the goal of identifying some new trends and patterns. These trends and patterns are then used to predict future outcomes and trends. By performing predictive analysis, we can predict future trends and performance. It is also defined as the prognostic analysis, the word prognostic means prediction. Predictive analytics uses the data, statistical algorithms and machine learning techniques to identify the probability of future outcomes based on historical data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6ocGWg6F8PJ"
      },
      "source": [
        "In predictive analysis, we use historical data to predict future outcomes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb80Q6UTGB_Q"
      },
      "source": [
        "Machine learning is the subject of AI that makes use of statistics, fundamentals of computer science and arithmetic to construct good judgment for algorithms to operate the project such as prediction and classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqXLVu-jGmpK"
      },
      "source": [
        " Predictive Analytics :\n",
        "It entails certain manipulations on statistics from current records units with the purpose of figuring out some (new traits and patterns)**bold text**.** These trends and patterns are then used to predict future results and trends. The sole purpose of this is to compute the value of a specific variable at a future factor of time. Predictive analytics is close information loaded whilst machine learning is more of a combination of statistics, programming, and mathematics.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es9AlWQfG5Ht"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWlPLDNgeJOS"
      },
      "source": [
        "Desition TRees \n",
        "When to use to decision tree:\n",
        "When you want your model to be simple and explainable *1\n",
        "When you want non parametric model*2\n",
        "When you don't want to worry about feature selection or regularization or worry about multi-collinearity.*3\n",
        "You can overfit the tree and build a model if you are sure of validation or test data set is going to be subset of training data set or almost overlapping instead of unexpected.*4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cDJo0zhuEcZ"
      },
      "source": [
        "When to use random forest :\n",
        "\n",
        "When you don't bother much about interpreting the model but want better accuracy.\n",
        "Random forest will reduce variance part of error rather than bias part, so on a given training data set decision tree may be more accurate than a random forest. But on an unexpected validation data set, Random forest always wins in terms of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c24LVJwvM1q"
      },
      "source": [
        "Feature engineering is the process of using domain knowledge to extract features from raw data. These features can be used to improve the performance of machine learning algorithms. Feature engineering can be considered as applied machine learning itself.\n",
        "In machine learning, features are individual independent variables that act like a input in your system. Actually, while making the predictions, models use such features to make the predictions. And using the feature engineering process, new features can also be obtained from old features in machine learning.\n",
        "Feature engineering is useful to improve the performance of machine learning algorithms\n",
        "For example, the decision tree based algorithms take into consideration only one feature at a time and divide the set into one part where the values of a considered feature are higher than an arbitrary threshold and the second part where values are lower.\n",
        "Feature engineering is the process of using data's domain knowledge to create features that make machine learning algorithms work (Wikipedia). It's the act of extracting important features from raw data and transforming them into formats that are suitable for machine learning.Jan 8, 2020\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O0cZpLeuiTw"
      },
      "source": [
        "Linear regression is used to predict the continuous dependent variable using a given set of independent variables. Logistic Regression is used to predict the categorical dependent variable using a given set of independent variables.\n",
        " Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables\n",
        "-----------------------------------------------------------------------\n",
        "The goal of logistic regression is to correctly predict the category of outcome for individual cases using the most parsimonious model. To accomplish this goal, a model is created that includes all predictor variables that are useful in predicting the response variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORpywtL10tB-"
      },
      "source": [
        " SVM is a supervised machine learning algorithm that is commonly used for classification and regression challenges. Common applications of the SVM algorithm are Intrusion Detection System, Handwriting Recognition, Protein Structure Prediction, Detecting Steganography in digital images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osxw7O494KvT"
      },
      "source": [
        "In the SVM algorithm, it is easy to classify using linear hyperplane between two classes. But the question arises here is should we add this feature of SVM to identify hyper-plane. So the answer is no, to solve this problem SVM has a technique that is commonly known as a kernel trick.\n",
        "\n",
        "(Kernel trick) is the function that transforms data into a suitable form. There are various types of kernel functions used in the SVM algorithm i.e. Polynomial, linear, non-linear, Radial Basis Function, etc. Here using kernel trick low dimensional input space is converted into a higher-dimensional space.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtNNhaS4H0b8"
      },
      "source": [
        "Naive Bayes is the most straightforward and fast classification algorithm, which is suitable for a large chunk of data. Naive Bayes classifier is successfully used in various applications such as spam filtering, text classification, sentiment analysis, and recommender systems. It uses Bayes theorem of probability for prediction of unknown class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmL-DO4JdoG"
      },
      "source": [
        "Naive Bayes is a statistical classification technique based on Bayes Theorem. It is one of the simplest supervised learning algorithms. Naive Bayes classifier is the fast, accurate and reliable algorithm. Naive Bayes classifiers have high accuracy and speed on large datasets.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGt0Lv9yTbco"
      },
      "source": [
        "First, you need to convert these string labels into numbers. for example: 'Overcast', 'Rainy', 'Sunny' as 0, 1, 2. This is known as label encoding. Scikit-learn provides LabelEncoder library for encoding labels with a value between 0 and one less than the number of discrete classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSqcVFueTe6Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHOnTaCzK8m-"
      },
      "source": [
        " #IMPORTANT#P(h|D): the probability of hypothesis h given the data D. This is known as posterior probability.\n",
        "P(h): the probability of hypothesis h being true (regardless of the data). This is known as the prior probability of h.\n",
        "P(D): the probability of the data (regardless of the hypothesis). This is known as the prior probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPK40W7DMLw7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HW2rC-LN0vxE"
      },
      "source": [
        "Pros of SVM Algorithm\n",
        "1)SVMs works great for text classification and when finding the best linear separator.\n",
        "2)It is useful to solve any complex problem with a suitable kernel function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnqUFILx3xW_"
      },
      "source": [
        "Cons:\n",
        "It takes a long training time when working with large datasets.\n",
        "It is hard to understand the final model and individual impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CZGmk0yUouh"
      },
      "source": [
        "flask is about web developing \n",
        "and flask is a frame work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m5NUOdDMC5Q"
      },
      "source": [
        "One-Hot Encoding\n",
        "For categorical variables where no such ordinal relationship exists, the integer encoding is not enough.\n",
        "In fact, using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n",
        "In this case, a one-hot encoding can be applied to the integer representation. This is where the integer encoded variable is removed and a new binary variable is added for each unique integer value."
      ]
    }
  ]
}